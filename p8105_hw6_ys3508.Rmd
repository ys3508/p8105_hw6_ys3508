---
title: "p8105_hw5_ys3508"
output: github_document
date: "2022-11-16"

---
# Writing Function
```{r}
library(tidyverse)
library(rvest)
library (readr)
library(plotly)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Problem 1
### Create a tidy dataframe
```{r}
file_names = list.files(path = "data/problem1", pattern = NULL, all.files = FALSE, full.names = TRUE)
```

Iterate over file names and read in data for each subject using purrr::map and saving the result as a new variable in the dataframe
```{r}
#using map + read_csv function
hw1 = map(file_names, read_csv)

for (i in 1:20) 
  {
  
  if (i < 11) {
    
    hw1 [[i]] = hw1 [[i]] %>% 
      mutate(
        subject_id = i,
        arm = "Control")
  }
  
  else {
    
    hw1 [[i]] = hw1 [[i]] %>% 
      mutate(
        subject_id = i - 10,
        arm = "Experimental")
  }
  
}

```
Tidy the result

```{r}
hw1_tidy = hw1 %>%
  bind_rows() %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    names_prefix = "week_",
    values_to = "observation"
  ) %>%  
  mutate(
    subject_id = as.character(subject_id),
    week = as.numeric(week)
  ) %>% 
  select(subject_id, arm, everything())
 
```

### Plot

```{r}
hw1_tidy %>% 
  ggplot(aes(x = week, y = observation, group = subject_id, colour = subject_id)) +
    labs(x = "Time in week", y = "Observations", color = "Control arm", title = "Observations on each subject over time") + 
    geom_line(size=0.5) +
    geom_point(size=2) +
    facet_grid(. ~ arm) +
    theme_bw() +
    theme(legend.position="bottom")

```

* The observation values for individuals in the experimental arm are greater on average than those in the control arm. Furthermore, there appears to be some growth in a fairly linear fashion over time for those in the experimental arm, but the observation value for those in the control arm tends to be more steady.

## Problem 2
### Import data
```{r}
urlfile="https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"

hw2 <-read_csv(url(urlfile))
```

* The 'hw2' dataset comprises 12 variables with a total of 52179 observations, detailing murder cases in various cities around the United States. These factors include the reported date and location, some victim information (name, race, age, and gender), and the homicide's ultimate disposition.

### Create a city_state variable/Summary

```{r}
hw2_homicides = hw2 %>% 
 mutate(
    state = str_to_upper(state),
    city_state = str_c(city, ", ", state),
    city_state = recode(city_state, "Tulsa, AL" = "Tulsa, OK"), #error in dataset;
    final_disposition =
          ifelse(disposition == "Closed by arrest" ,"solved", "unsolved")) 

 

hw2_summary = hw2_homicides %>%
  group_by(city_state) %>% 
  summarise(
    total_homicides = n(),
    unsolved_homicides = sum(final_disposition == "unsolved")
  ) %>% 
  knitr::kable(
    col.names = c("City, State", "Total Number of Homicides", "Number of Unsolved Homicides")
  )
hw2_summary
```

###  `prop.test` function for MD

```{r}

hw2_md = hw2_homicides %>% 
  filter(city_state == "Baltimore, MD") 

prop_test = prop.test(1825,2827, conf.level=0.95, correct=FALSE)

broom::tidy(prop_test)

prop_test[["estimate"]]
prop_test[["conf.int"]]

```

* Using `prop_test[["estimate"]]` and `prop_test[["conf.int"]]` to get the estimate of 0.6455607 and confidence intervals from 0.6275625 to 0.6631599.

### Using `map` for `prop.test`
define the `prop_test` function
```{r}
    
prop_test = function(dataset) {
  
  prop_test = dataset %>%
  summarise(
    total_homicides = n(),
    unsolved_homicides = sum(final_disposition == "unsolved")
  )
  
  test = prop.test(
      prop_test$unsolved_homicides, 
      prop_test$total_homicides, 
      conf.level = 0.95, correct=FALSE
      ) %>% 
    broom::tidy()
   
  test
}

```

use `nest` and `map`
```{r}

  
hw2_nest = hw2_homicides %>%
  select(city_state, everything()) %>% 
  nest(data = uid:final_disposition) 

hw2_unsolved = hw2_nest %>% 
   mutate(test_result = map(data, prop_test)) %>% 
   unnest(test_result) 

hw2_unsolved%>% 
  select(city_state, estimate, conf.low, conf.high) %>% 
   knitr::kable(digits = 3)


```

### Plot
```{r}
hw2_unsolved %>% 
  mutate(
    city_state = fct_reorder(city_state, estimate)) %>% 
ggplot(aes(x=city_state, y=estimate )) + 
  geom_point() +
  geom_errorbar(aes(ymin=conf.low, ymax=conf.high), width=.2,
                 position=position_dodge(.9))+
  labs(title="The estimates and CIs for proportion of unsolved homicides for each city", x="City and state", y = "Estimtate")+
  theme(axis.text.x = element_text(angle = 90))



```

## Problem 3
### t-test
`t_test` function:

```{r}

t_test = function(n = 30, mu, sigma = 5) {
  
  x = rnorm(n, mean = mu, sd = sigma)
  
  t_test =
    t.test(x, mu = 0) %>% 
    broom::tidy() 
  
  t_test %>% 
    select(estimate, p.value)
  
}

```

Generate 5000 datasets from the model:

```{r}
t_results =
  rerun(5000, t_test(mu = 0)) %>%  #generate 5000 dataset;
  bind_rows()


```

Repeat the above for μ={1,2,3,4,5,6}:

```{r, cache = TRUE}
t_results_df = 
  expand_grid(
    true_mu = c(1, 2, 3, 4, 5, 6),
    iteration = 1:5000
  ) %>% 
  mutate(
    estimate_df = map(.x = true_mu, ~ t_test (mu = .x))
  ) %>% 
  unnest(estimate_df)

```

### Plot1
Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of μ on the x axis. Describe the association between effect size and power.

```{r}

t_plot1 = t_results_df %>% 
  mutate(
    result = ifelse(p.value < 0.05, "Reject", "Fail to reject"
    )) %>% 
  group_by(true_mu) %>% 
  summarize(
    total = n(),
    reject = sum(result == "Reject")
  ) %>% 
  mutate(
    prop_reject_null = reject / total
  ) 
  
t_plot1 %>% 
    ggplot(aes(x = true_mu, y = prop_reject_null)) +
    geom_point() +
    geom_line() +
    labs(
   title = "The relashinship between power of the test and ture μ" ,
   x = "Ture μ value" ,
   y = "The power of the test")


```

* The power, or the percentage of times the null was rejected, will grow as the effect size, or the true mu, increases.

### Plot2
Make a plot showing the average estimate of μ̂  on the y axis and the true value of μ on the x axis. Make a second plot (or overlay on the first) the average estimate of μ̂  only in samples for which the null was rejected on the y axis and the true value of μ on the x axis. 


```{r}
t_plot2 = t_results_df %>% 
  group_by(true_mu) %>% 
  summarise(avg_estimate_mu = mean(estimate))

t_plot3 = t_results_df %>% 
  mutate(
    result = ifelse(p.value < 0.05, "Reject", "Fail to reject"
    )) %>% 
  filter(result == "Reject") %>% 
  group_by(true_mu) %>% 
  summarise(avg_estimate_mu = mean(estimate))

ggplot(t_plot2, aes(x = true_mu, y = avg_estimate_mu)) +
  geom_point() +
  geom_line() +
  geom_point(data = t_plot3, color = "pink") +
  geom_line(data = t_plot3, color = "pink") +
  labs(
    title = "Average estimate of μ_hat vs. ture μ",
    x = "True mu",
    y = "Average estimate of mu_hat")  

```

```{r}

t_plot2 %>% 
    plot_ly(
    x = ~ true_mu, y = ~ avg_estimate_mu, type = "scatter", mode = "lines+markers", 
    alpha = 0.5) %>% 
    layout(title = 'Average estimate of μ_hat vs. ture μ', plot_bgcolor = "#e5ecf6", xaxis = list(title = 'Ture μ value'), 
         yaxis = list(title = 'Average estimate of μ_hat'))

t_plot3 %>% 
    plot_ly(
    x = ~ true_mu, y = ~ avg_estimate_mu, type = "scatter", mode = "lines+markers",
    alpha = 0.5) %>% 
    layout(title = 'Average estimate of μ_hat when refect Null vs. ture μ', plot_bgcolor = "#e5ecf6", xaxis = list(title = 'Ture μ value'), 
         yaxis = list(title = 'Average estimate of μ_hat'))

```

* The sample average of mu estimtate across tests for which the null hypothesis is rejected is not nearly equivalent to the true value when the value of mu is small. The average of mu, however, is closer to true mu as true mu increases, i.e., the sample average is becoming closer and closer to the true value.


* Reasons:

* When true mu is small, which means the effect size is small, the power is low, and fewer samples are rejected, leading to a larger average estimate compared to the true value.

* When true mu is increasing, which means the effect size is increasing, the power is increasing, and more samples are rejected, leading to a closer average estimate compared to the true value.